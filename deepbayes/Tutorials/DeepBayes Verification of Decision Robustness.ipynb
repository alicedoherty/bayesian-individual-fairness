{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Bounds on Posterior Predictive Decision Probability with DeepBayes\n",
    "\n",
    "Posterior Predictive: $p(y^* | x^*, X, Y) = \\int p(y^{*} | x^{*}, \\theta)p(\\theta | X, Y) d\\theta$\n",
    "\n",
    "Here we walk through the code to compute upper and lower bounds on $p(y^* | x^*, X, Y)$ \n",
    "\n",
    "#### Example notebook takes 3 minutes to run in total\n",
    "(Times are reported for an M1 Pro Macbook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import deepbayes\n",
    "from deepbayes import PosteriorModel\n",
    "from deepbayes.analyzers import decision_veri\n",
    "from deepbayes.analyzers import FGSM\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train/255.\n",
    "X_test = X_test/255.\n",
    "X_train = X_train.astype(\"float64\").reshape(-1, 28*28)\n",
    "X_test = X_test.astype(\"float64\").reshape(-1, 28* 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We define predicate for safety and worst-case logit values\n",
    "\n",
    "The logit value defines the worst-case logit acheivable for a given input set and \n",
    "weight set. The lower bound proceedure then combines all of this information with \n",
    "the posterior probabilities of the weight sets to get a valid lower bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicate_safe(iml, imu, ol, ou):\n",
    "    return True\n",
    "    v1 = tf.one_hot(TRUE_VALUE, depth=10)\n",
    "    v2 = 1 - tf.one_hot(TRUE_VALUE, depth=10)\n",
    "    v1 = tf.squeeze(v1); v2 = tf.squeeze(v2)\n",
    "    worst_case = tf.math.add(tf.math.multiply(v2, ou), tf.math.multiply(v1, ol))\n",
    "    if(np.argmax(worst_case) == TRUE_VALUE):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def logit_value(iml, imu, ol, ou):\n",
    "    v1 = tf.one_hot(TRUE_VALUE, depth=10)\n",
    "    v2 = 1 - tf.one_hot(TRUE_VALUE, depth=10)\n",
    "    v1 = tf.squeeze(v1); v2 = tf.squeeze(v2)\n",
    "    worst_case = tf.math.add(tf.math.multiply(v2, ou), tf.math.multiply(v1, ol))\n",
    "    worst_case = tf.nn.softmax(worst_case)\n",
    "    return worst_case[TRUE_VALUE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in our pre-trained BNN posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1, 128)            100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1, 10)             1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "BayesKeras detected the above model \n",
      " None\n"
     ]
    }
   ],
   "source": [
    "bayes_model = PosteriorModel(\"PosteriorModels/VOGN_MNIST_Posterior/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select an image that we would like to verify the robustness of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = 1\n",
    "img = np.asarray([X_test[INDEX]])\n",
    "TRUE_VALUE = np.argmax(bayes_model.predict(np.asarray([img]))) #y_test[INDEX]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Verification Parameters and compute Decision Lower Bound\n",
    "\n",
    "##### Parameters: \n",
    "* Margin - The number of standard deviations that each weight sample will span\n",
    "* Samples - The number of samples taken from the posterior (Small here for time savings)\n",
    "* Max Depth - The depth of the Bonferroni Bound used to compute the probability\n",
    "* Epsilon - The size of the input set that we consider for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Checking Samples:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--  tf.Tensor(0.98579246, shape=(), dtype=float32)\n",
      "--  tf.Tensor(0.9856289, shape=(), dtype=float32)\n",
      "--  tf.Tensor(0.98577034, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking Samples: 100%|██████████| 3/3 [00:00<00:00, 105.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 safe intervals\n",
      "About to compute intersection for this many intervals:  3\n",
      "GOT THIS MANY VALUES:  3 [0.98579246 0.9856289  0.98577034]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing intersection weights:   0%|          | 0/3 [00:00<?, ?it/s]/Users/matthewwicker/AdversarialRobustnessOfBNNs/deepbayes/analyzers/probverification.py:496: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  stage1_args.append((model.posterior_mean, model.posterior_var, np.swapaxes(np.asarray([weight_intervals[wi]]),1,0), margin, verbose, n_proc, False))\n",
      "Computing intersection weights: 100%|██████████| 3/3 [00:00<00:00, 5282.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth 1 has 3 intersections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:25<00:00,  8.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9203388856672858, 0.9256142326759657, 0.9078951361373474] [0.98579246 0.9856289  0.98577034]\n",
      "Depth 1 prob:  2.753848254480599 logit val:  2.7145513743526486\n",
      "Depth 2 has 3 intersections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:29<00:00,  9.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current prob:  0.2255570033916241  Current dec:  0.22219976891232074\n",
      "Depth 3 has 1 intersections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:27<00:00, 27.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current prob:  0.9994163431619119  Current dec:  0.9850473570534515\n",
      "Got this approximation:  0.9994163431619119\n",
      "Lowerbound on Decision Probability:  0.9844724274276666\n"
     ]
    }
   ],
   "source": [
    "MARGIN = 3.5\n",
    "SAMPLES = 3\n",
    "MAXDEPTH = 3\n",
    "EPSILON = 0.01\n",
    "img = np.asarray([X_test[INDEX]])\n",
    "img_upper = np.clip(np.asarray([X_test[INDEX]+(EPSILON)]), 0, 1)\n",
    "img_lower = np.clip(np.asarray([X_test[INDEX]-(EPSILON)]), 0, 1)\n",
    "p_lower = decision_veri(bayes_model, img_lower, img_upper, MARGIN, SAMPLES, predicate=predicate_safe, value=logit_value, depth=MAXDEPTH)\n",
    "print(\"Lowerbound on Decision Probability: \", p_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicate_safe(iml, imu, ol, ou):\n",
    "    return True\n",
    "\n",
    "def logit_value(iml, imu, ol, ou):\n",
    "    v1 = tf.one_hot(TRUE_VALUE, depth=10)\n",
    "    v2 = 1 - tf.one_hot(TRUE_VALUE, depth=10)\n",
    "    v1 = tf.squeeze(v1); v2 = tf.squeeze(v2)\n",
    "    #best_case = tf.math.add(tf.math.multiply(v2, ou), tf.math.multiply(v1, ol))\n",
    "    #best_case = tf.nn.softmax(best_case)\n",
    "    best_case = tf.math.add(tf.math.multiply(v1, ou), tf.math.multiply(v2, ol))\n",
    "    best_case = tf.nn.softmax(best_case)\n",
    "    return best_case[TRUE_VALUE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Verification Parameters and compute Decision Upper Bound\n",
    "\n",
    "##### Parameters: \n",
    "* Margin - The number of standard deviations that each weight sample will span\n",
    "* Samples - The number of samples taken from the posterior (Small here for time savings)\n",
    "* Max Depth - The depth of the Bonferroni Bound used to compute the probability\n",
    "* Epsilon - The size of the input set that we consider for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking Samples: 100%|██████████| 3/3 [00:04<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 safe intervals\n",
      "About to compute intersection for this many intervals:  3\n",
      "GOT THIS MANY VALUES:  3 [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing intersection weights: 100%|██████████| 3/3 [00:00<00:00, 50131.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth 1 has 3 intersections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:25<00:00,  8.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1266824459031524, 0.09092414159744076, 0.10592504729348824] [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
      "Depth 1 prob:  0.32353163479408137 logit val:  0.32353163479408137\n",
      "Depth 2 has 3 intersections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:29<00:00, 10.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current prob:  0.28812130687441734  Current dec:  0.28812130687441734\n",
      "Depth 3 has 1 intersections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:27<00:00, 27.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current prob:  0.2894305255215826  Current dec:  0.2894305255215826\n",
      "Got this approximation:  0.2894305255215826\n",
      "Upperbound on Decision Probability:  0.7943395035821169\n"
     ]
    }
   ],
   "source": [
    "from deepbayes.analyzers import decision_veri_upper\n",
    "INDEX = 1\n",
    "EPSILON = 0.15\n",
    "MARGIN = 3.0\n",
    "img = np.asarray([X_test[INDEX]])\n",
    "img_upper = np.clip(np.asarray([X_test[INDEX]+(EPSILON)]), 0, 1)\n",
    "img_lower = np.clip(np.asarray([X_test[INDEX]-(EPSILON)]), 0, 1)\n",
    "p_upper = decision_veri_upper(bayes_model, img_lower, img_upper, MARGIN, SAMPLES, predicate=predicate_safe, value=logit_value, depth=MAXDEPTH)\n",
    "print(\"Upperbound on Decision Probability: \", p_upper)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
