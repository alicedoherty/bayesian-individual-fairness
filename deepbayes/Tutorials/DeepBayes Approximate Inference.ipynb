{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a BNN with 20 lines of code in 20 seconds\n",
    "\n",
    "### In this notebook we demonstrate how simple it is to perform approximate inference using DeepBayes\n",
    "\n",
    "(Time reported from a M1 Pro Macbook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepbayes\n",
    "import deepbayes.optimizers as optimizers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we load in and normalize the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train/255.\n",
    "X_test = X_test/255.\n",
    "X_train = X_train.astype(\"float32\").reshape(-1, 28*28)\n",
    "X_test = X_test.astype(\"float32\").reshape(-1, 28* 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We define a model using the flexible Keras interface\n",
    "(Most valid Keras models are also valid DeepBayes models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation=\"relu\", input_shape=(1, 28*28)))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We then select the inference method and key parameters for a run\n",
    "Calling compile will set up the DeepBayes model\n",
    "\n",
    "Calling train will then perform inference over the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This optimizer does not have a default compilation method. Please make sure to call the correct .compile method before use.\n",
      "deepbayes: Using implicit prior\n",
      "(784, 128) 0.03571428571428571\n",
      "(128, 10) 0.08838834764831845\n",
      "deepbayes: Using implicit prior\n",
      "(784, 128) 0.03571428571428571\n",
      "(128, 10) 0.08838834764831845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/469 [00:00<?, ?it/s]/Users/matthewwicker/AdversarialRobustnessOfBNNs/deepbayes/optimizers/blrvi.py:68: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  self.model.set_weights(np.asarray(init_weights))\n",
      "/Users/matthewwicker/AdversarialRobustnessOfBNNs/deepbayes/optimizers/blrvi.py:135: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  g = np.asarray(weight_gradient)\n",
      "100%|██████████| 469/469 [00:05<00:00, 92.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss: 0.833, acc: 0.782, val_loss: 0.670, val_acc: 0.882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:05<00:00, 88.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, loss: 0.692, acc: 0.867, val_loss: 0.528, val_acc: 0.894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:05<00:00, 93.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, loss: 0.445, acc: 0.901, val_loss: 0.310, val_acc: 0.908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:04<00:00, 94.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, loss: 0.283, acc: 0.922, val_loss: 0.268, val_acc: 0.933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:04<00:00, 94.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, loss: 0.225, acc: 0.942, val_loss: 0.205, val_acc: 0.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:04<00:00, 94.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, loss: 0.166, acc: 0.952, val_loss: 0.186, val_acc: 0.952\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.35; decay=0.0\n",
    "opt = optimizers.VariationalOnlineGuassNewton()\n",
    "bayes_model = opt.compile(model, loss_fn=loss, epochs=5, learning_rate=learning_rate, batch_size=128)\n",
    "bayes_model.train(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, we can save the resulting posterior. This will create a new directory and store all the posterior information for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('classes', 10)\n",
      "('batch_size', 128)\n",
      "('learning_rate', 0.35)\n",
      "('decay', 0.0)\n",
      "('epochs', 6)\n",
      "('inflate_prior', 1)\n",
      "('input_noise', 0.0)\n",
      "('robust_train', 0)\n",
      "('epsilon', 0.09999999999999999)\n",
      "('robust_lambda', 0.5)\n",
      "('loss_monte_carlo', 2)\n",
      "('input_upper', inf)\n",
      "('input_lower', -inf)\n",
      "('beta_1', 0.999)\n",
      "('beta_2', 0.9999)\n",
      "('lam', 1.0)\n",
      "('N', 60000)\n",
      "('max_eps', 0.1)\n",
      "('max_robust_lambda', 0.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewwicker/AdversarialRobustnessOfBNNs/deepbayes/optimizers/optimizer.py:262: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.save(path+\"/mean\", np.asarray(self.posterior_mean))\n",
      "/Users/matthewwicker/AdversarialRobustnessOfBNNs/deepbayes/optimizers/optimizer.py:263: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.save(path+\"/var\", np.asarray(self.posterior_var))\n"
     ]
    }
   ],
   "source": [
    "bayes_model.save(\"PosteriorModels/VOGN_MNIST_Posterior\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
